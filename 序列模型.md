```python
数学符号定义：
  <Tx>：在左上角表示训练样本的第几个序列
```

```python
递归神经网络（循环神经网络）：正向传播
  首先有一个0向量激活a[0]，有x<i>对应输出yhat<i>，然后每个网络层，在输入a<i>和x<i>后激活得到下一个a<i+1>作为激活向量输入到下一个序列的输入层中（一般a[0]是向量0）
  a<i>=g(Waaa<i-1>+Waxx<i>+ba)------------Waa,Wax,ba中的a存在疑问（符号修改：=g(Wa[a<i-1>,x<i>]+ba)，其中Wa表示是Waa和Wax堆叠的向量，其实这样子使用dot计算很快）
  yhat<i>=g(wyaa<i>+by)---------------相同的存在疑问
  激活函数在RNN中一般使用tanh，宽松使用RELU

  疑问解答:
    Wa是一个参数，ba也是一个相关网络的参数，Waa的意思是这个参数要和a这个向量进行计算
    Wy和by同理
```

```python
RNN反向传播：
  
```

```python
RNN多种架构：（只是例子）
  1.一对多：输入一个输出多个
    只有一个输入，将输入的输出yhat<1>以及a<1>输出后，将yhat作为下一层数输入x<i>（相当于）
  2.多对多：输入输出的长度不一样
    将所有的x进行输入后，继续进行网络，包含输入的网络叫做encode，后面的叫做decode，操作相当于先将所有句子读完，然后再进行分析输出
  3.多对一：
    相当于只输出一个yhat在最后面
  4.多对多：输入输出一样
    不做论述
```

```python
语言模型和序列生成：
  很抽象，听不懂，感觉不是很必要
```

```python
双向RNN：BRNN
  问题：如何判断泰迪是熊还是人名的一部分，使用GRU、LSTM这种也不行，因为依然是单向传播
  结构：在传统的RNN中添加了向前递归的单元
```

```python
NLP开始标记
```
```python
词汇表征：
  问题：在传统的使用单词表向量表示的方法会有问题，如果在对一个单词的联系之间进行计算，由于欧几里得距离全是相同的很难判别
        如何让相近的东西的单词联系起来可以加速神经网络的学习和计算

  嵌入词表示：
    将单词嵌入到一个多维度的表示中，相似的单词在距离上是相近的表示相似

  嵌入矩阵：
    E表示嵌入矩阵（需要梯度下降学习），Oj表示相关单词j的向量表示（就是在某一个位置是1，其他是0），ej表示相关单词j的嵌入向量
    ej=np.dot(E,Oj)
    但是在实际中我们不会这样相乘，因为这样的代价很大，实际中使用查找的方法进行点成，因为热向量Oj中只有一个是1，其余全是0
```



























