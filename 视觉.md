```python
边缘检测：
  垂直边缘检测：卷积核使用的是垂直排列的方式，比如左边是1中间是0右边是-1这种（卷积核是3*3大小），可以在图像中找到垂直的线（边缘）
  注：在RBG中低数值的颜色比较深，高颜色比较亮

  深度学习边缘检测：将卷积核中的数值设定成为参数，并学习这些参数进行边缘检测，相比于手工进行卷积核数值的填写更好实现边缘检测（多角度的边缘检测）
```

```python
PADDING
  卷积操作有缺点，在进行操作的时候边缘的信息使用的很少（甚至只有一次），并且如果在深层网络中一直使用卷积操作就会一直将图像缩小。
  想到的是在周围填充（比如在周围填充一个像素边框全是0，padding=1）

卷积就分成了两种：
  1.有效卷积：就是没有填充
  2.相同卷积：填充后输入和输出的特征图大小相同

在计算机视觉中使用奇数的滤波器（卷积核）
```

```python
卷积步长（strided）：
  步长就是卷积核移动的距离
```

```python
三维卷积：
  例子：现在假设输入图片是RGB三个通道，三维卷积将原先的一维卷积（比如：3*3*1）变成（3*3*3，其中最后的3是通道数量，要和输入的通道数量保持一致）三维卷积核，但是最后的图像输出是二维的（比如4*4*1）。

  卷积过程：每个通道上对应的卷积核和对应输入图像通道上的图像进行卷积操作，然后将他们进行相加得到最后的输出（相当于降维操作）

卷积的符号：
f：滤波器的尺寸
p：padding
s：步长
```

```python
卷积层的类型：
  1.卷积层：CONV

  2.池化层：POOL（没有要学习的参数，梯度下降不变）----------尺寸和大小
    使用来减小表达的大小，加速计算，使检测到的特征更加稳定
    最大池化：拿到决定范围中最大的值进行输出
    平均池化：平均值作为输出

  3.全连接层：FC
```

```python
目标检测：
  目标检测是识别和定位的融合，需要的参数有：label（识别的标签），bx(目标定位)，by(定位)，bh(目标高度)，bw(目标的长度)

  识别：使用卷积进行识别
  定位：使用滑动窗口检测算法（相当于一个框在从头进行移动检测）------------但是计算成本很高，需要使用不一样的窗口大小裁剪输入，但是可以解决

  当前的滑动窗口：使用整个图，将整个图输出，相当于把输入网格化，一个格子卷积的结果相当于一个窗口的输出（问题：检测边框的准确问题）

  检测边框的准确（YOLO算法）：
    1.定位：将图像输入分为几个网格，定位相关物体的中心（只看一次，就是即使在另一个网格中有部分，但是也将那边网格的物体检测向量为false）
    2.框框：设定每个网格的长和宽都是1，所以不是跨网格的物体框框长宽<1。

  YOLO简单概括：分成几个网格，然后由物体中心点所在的网格做输出，框框是网络自己计算出来的，相当于YOLO是分配输出网格任务的算法，作为Pc=true部分（自己理解的）
```

```python
非极大值抑制（NMS）：一种确保算法仅检测每个对象一次的方法
  简单说：就是将重叠的识别框，将概率低的PASS，留下那个最高的

  算法细节：
    1.首先每个网格进行检测，输出的向量有一个输出的概率（Pc），将小于一定概率的框框丢弃
    2.循环：拿到概率大的框最为预测，将存在的框尽心计算IoU（并交值），将大于一定值的框丢弃
```

```python
锚框（anchor box）：想让一个网格识别多个物体（现在YOLO相当于将它进行调整输出的）
  输出的向量更加长，使用几个锚框就多几倍向量长度

  每个网格有几个锚框神经网络将它中心点，后进行偏移大小调整进行预测（现代YOLO）
```

```python
人脸识别：
  ONE-SHORT LREANING(一次学习)：要解决的问题
    学习相似函数

  三元组损失（TRIPLET）：锚点A，正例P，反例N
    损失=max（【(||f(A)-f(P)||^2)-(||f(A)-f(N)||^2)+α<=0】，0）

  也有使用二分类进行判断的方法：输入两个图像分别计算得到输出，在将输出进入一个新的网络判断是不是同一个人
```

```python

```

















